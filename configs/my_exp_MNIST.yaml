# This file serves as the configurations for the benchmarking experiments, including the basic configuration and the parameters for all attacks and defenses that are going to be tested. You can copy this file and modify it to run your own single attack and defense experiments.
seed: 4 # seed for reproducibility
# basic configuration
algorithm: FedSGD # algorithm, FedSGD, FedAvg, FedOpt
optimizer: SGD # optimizer for training
momentum: 0.9
weight_decay: 5.0e-4
# lr_scheduler: MultiStepLR # learning rate scheduler
# milestones: [0.6, 0.8] # milestones for learning rate scheduler
batch_size: 32 # batch_size
learning_rate: 0.01 # clients' local learning rate
model: lenet # model architecture
dataset: MNIST # dataset
distribution: iid # data distribution
im_iid_gamma: 0.01 # For class-imbalanced iid, smaller gamma, stronger imbalance, 0.5, 0.6 reference: centered clipping
tail_cls_from: 4 # For class-imbalanced iid, the tail classes start from 4
dirichlet_alpha: 0.2 # For non-iid, smaller alpha, stronger heterogeneity, normally use 0.1, 0.5, 0.9, 1
cache_partition: False # whether to cache the partitioned client indices
num_workers: 0
record_time: False
gpu_idx: [3] # Indices of GPU

my_exp: True # 我的实验开关
epochs: 200 # global epochs
predict_epochs: 5 # 指数平滑使用前几轮的全局模型平均来作为s的初始值
predict_alpha: 0.8 # 预测全局模型的指数平滑超参数
hyper_e: 50 # 攻击的假设检验间隔
softmax_seg: "Min" # 间隔的方式

show_sign_flip: True # 画第三章的符号翻转示意图，是否开启保存数据
other_show_3d: False # 其他防御方法输出良性和恶意客户端的3d图片(只选第一个和最后一个客户端) 
only_show_last_epoch: True # 只打印最后一轮的结果

# ！！！每次实验一定要换位置，不然保存在别的位置不好找了！！
npy_file_name: 3.3.2
npy_prefix: None  # acc,sign-flip 暂时没用到

# general attack settings
num_clients: 30 # number of participating clients
num_adv: 0.2 # the proportion (float < 1) or number (int>1) of adversaries

attack: MyAttack
defense: NormClipping

# ! Please follow the format below to specify the attack and defense settings
# ! for attacks, `num_adv` should be specified, and `attack_params` should be specified with the corresponding parameters.
# ! Note that for backdoor attacks, you should specify the backdoor strategy, ['all2one', 'all2all', 'targeted'] and corresponding parameters, `poisoning_ratio` and [`source_label`, `target_label`] for targeted, `target_label` for all2one, nothing for all2all.

attacks:
    - attack: MyAttack
      attack_params:
          # 我的攻击方案参数
          aff_open: False # 是否开启牺牲客户端，没啥用
          moment_open: True # 是否开启动量
          record_sign_match: False # 是否记录更新符号匹配

    - attack: NoAttack
    - attack: SignFlipping
    - attack: MPAF
      attack_params:
          lamda: 1e5
    - attack: IPM
      attack_params: # Parameters for attacks
          scaling_factor: 0.5 # 0.5, 100
          # attack_start_epoch: 11
    - attack: ALIE
      # attack_params:
      #     attack_start_epoch: 41
    - attack: Gaussian
      attack_params:
          noise_mean: 0
          noise_std: 1
    - attack: Mimic
      attack_params:
          choice: 0
    - attack: MinMax
      attack_params:
          gamma_init: 10
          stop_threshold: 1.0e-5 # !!YAML specification: for scientific notation, write the base number as a float (e.g. 1.0) and add the sign to the exponent (e.g. +1,-1), such as 1.0e+5
    - attack: MinSum
      attack_params:
          gamma_init: 10
          stop_threshold: 1.0e-5
    - attack: FangAttack
      attack_params:
          stop_threshold: 1.0e-5
    - attack: BadNets
      attack_params:
          trigger_size: 5
          attack_model: "all2one" # all2one, all2all, targeted, random
          poisoning_ratio: 0.32 # poisoning portion
          target_label: 7 # The No. of target label for backdoored images
          attack_strategy: continuous #  attack_strategy: ['single-shot', 'fixed-frequency','continuous'], `poison_frequency` for fixed-frequency
          # attack_start_epoch: 21
    - attack: BadNets_image
      attack_params:
          trigger_path: ./attackers/triggers/trigger_white.png # Trigger Path
          trigger_size: 5 # Trigger Size
          attack_model: "all2one"
          poisoning_ratio: 0.32 # poisoning portion
          target_label: 7 # The No. of target label for backdoored images
          attack_strategy: continuous
    - attack: LabelFlipping
      attack_params:
          attack_model: "targeted" # "targeted" will not affect by poisoning_ratio, because it will flip only the source labels in a batch
          source_label: 3 # in our non-iid partiton, label=3 is owned by all clients
          target_label: 7
          attack_strategy: "continuous"
          # poisoning_ratio: 0.25 # poisoning portion
    - attack: ModelReplacement
      attack_params:
          scaling_factor: 50 # estimated scaling factor, num_participants / global_lr
          alpha: 0.5
          attack_model": "all2one"
          poisoning_ratio": 0.32
          source_label: 2
          target_label: 7
          attack_strategy: "continuous"
    - attack: DBA
      attack_params:
          attack_model: "all2one"
          scaling_factor: 100
          trigger_factor: [8, 2, 0] # 8,2,0 for MNIST, 10,3,0 for CIFAR10
          poisoning_ratio: 0.32
          source_label: 2
          target_label: 7
          attack_strategy: "continuous" # "fixed-frequency"
          # poison_frequency: 10
          # attack_start_epoch: 150
    - attack: EdgeCase
      attack_params:
          poisoning_ratio: 0.5
          epsilon: 0.25 # For PGD with replacement, 0.25 for mnist, 0.083 for cifar10
          projection_type: "l_2"
          l2_proj_frequency: 1
          scaling_attack: True
          scaling_factor: 50
          target_label: 1 # mnist 1, cifar10 9
    - attack: Neurotoxin
      attack_params:
          num_sample: 64
          topk_ratio: 0.1
          norm_threshold: 0.2
          attack_model: "all2one"
          poisoning_ratio: 0.32
          source_label: 1
          target_label: 6
          attack_strategy: "continuous"
    - attack: AlterMin
      attack_params:
          attack_model: targeted
          poisoned_sample_cnt: 1
          boosting_factor: 50
          rho: 1.0e-4
          benign_epochs: 10
          malicous_epochs: 1
          source_label: 3
          target_label: 7

defenses:
    - defense: Mean
    - defense: SimpleClustering
    - defense: Krum
      defense_params:
          enable_check: False
    - defense: MultiKrum
      defense_params:
          avg_percentage: 0.2
          enable_check: False
    - defense: TrimmedMean
      defense_params:
          beta: 0.1
    - defense: Median
    - defense: Bulyan
      defense_params:
          enable_check: False
    - defense: RFA
      defense_params:
          num_iters: 3
          epsilon: 1.0e-6
    - defense: FLTrust
      defense_params:
          num_sample: 100
    - defense: CenteredClipping
      defense_params:
          norm_threshold: 100
          num_iters: 1
    - defense: DnC
      defense_params:
          subsample_frac: 0.2
          num_iters: 5
          fliter_frac: 1.0
    - defense: Bucketing
      defense_params:
          bucket_size: 2
          selected_aggregator: "Krum"
    - defense: SignGuard
      defense_params:
          lower_bound: 0.1
          upper_bound: 3.0
          selection_fraction: 0.1
          clustering: "MeanShift"
          random_seed: 2
    - defense: LASA
      defense_params:
          norm_bound: 2
          sign_bound: 1
          sparsity: 0.3
    - defense: Auror
      defense_params: # Parameters for defenses
          indicative_threshold: 1.0e-4
          indicative_find_epoch: 10
    - defense: FoolsGold
      defense_params:
          epsilon: 1.0e-5
          topk_ratio: 0.1
    - defense: Bucketing
      defense_params:
          bucket_size: 2
          selected_aggregator: Krum
    - defense: NormClipping # weak differential privacy=norm clipping + differential privacy
      defense_params:
          weakDP: True
          norm_threshold: 3
          noise_mean: 0
          noise_std: 0.002
    - defense: CRFL
      defense_params:
          norm_threshold: 3
          noise_mean: 0
          noise_std: 0.001
    - defense: DeepSight
      defense_params:
          num_seeds: 3
          threshold_factor: 0.01
          num_samples: 20000
          tau: 0.33
          epsilon: 1.0e-6
    - defense: FLAME
      defense_params:
          gamma: 1.2e-5
    - defense: MyDefense
      defense_params:
          show_3d: False
          metric: euclidean # 聚类评估函数
          gamma: 0.99 # rs分数衰减系数
          recored_rs: False

    - defense: TESSERACT
      defense_params:
