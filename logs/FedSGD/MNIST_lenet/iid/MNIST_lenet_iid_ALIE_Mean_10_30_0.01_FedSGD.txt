seed: 4, epochs: 10, algorithm: FedSGD, optimizer: SGD, momentum: 0.9, weight_decay: 0.0005, num_clients: 30, batch_size: 64, learning_rate: 0.01, model: lenet, dataset: MNIST, distribution: iid, im_iid_gamma: 0.01, tail_cls_from: 4, dirichlet_alpha: 0.5, cache_partition: False, gpu_idx: [0], num_workers: 0, record_time: False, my_exp: True, predict_epochs: 5, num_adv: 6, attack: ALIE, defense: Mean, attack_params: None, defense_params: None, benchmark: False, num_training_sample: 60000, num_channels: 1, num_classes: 10, mean: (0.1307,), std: (0.3081,), device: cuda:0, output: ./logs/FedSGD/MNIST_lenet/iid/MNIST_lenet_iid_ALIE_Mean_10_30_0.01_FedSGD.txt

Started on Mon Feb 17 19:19:15 2025
Generating new indices
Doing iid partition
iid partition finished
Data partitioned
Clients and server are initialized
Starting Training...
Epoch 0  		Train Acc: 0.0958	Train loss: 0.0360	Test Acc: 0.0925	Test loss: 0.0362
Epoch 1  		Train Acc: 0.0927	Train loss: 0.0359	Test Acc: 0.0925	Test loss: 0.0362
Epoch 2  		Train Acc: 0.0911	Train loss: 0.0360	Test Acc: 0.0930	Test loss: 0.0361
Epoch 3  		Train Acc: 0.0984	Train loss: 0.0360	Test Acc: 0.0938	Test loss: 0.0361
Epoch 4  		Train Acc: 0.0755	Train loss: 0.0360	Test Acc: 0.0946	Test loss: 0.0361
Epoch 5  		Train Acc: 0.0839	Train loss: 0.0360	Test Acc: 0.0955	Test loss: 0.0361
Epoch 6  		Train Acc: 0.1021	Train loss: 0.0360	Test Acc: 0.0962	Test loss: 0.0361
Epoch 7  		Train Acc: 0.0870	Train loss: 0.0359	Test Acc: 0.0980	Test loss: 0.0361
Epoch 8  		Train Acc: 0.0859	Train loss: 0.0358	Test Acc: 0.0988	Test loss: 0.0360
Epoch 9  		Train Acc: 0.0896	Train loss: 0.0359	Test Acc: 0.0994	Test loss: 0.0360
Training finished on Mon Feb 17 19:20:25 2025 using 1 minutes and 10 seconds in total.
