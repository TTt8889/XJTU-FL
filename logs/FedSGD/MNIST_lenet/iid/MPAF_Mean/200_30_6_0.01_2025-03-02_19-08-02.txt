seed: 4, algorithm: FedSGD, optimizer: SGD, momentum: 0.9, weight_decay: 0.0005, batch_size: 32, learning_rate: 0.01, model: lenet, dataset: MNIST, distribution: iid, im_iid_gamma: 0.01, tail_cls_from: 4, dirichlet_alpha: 0.2, cache_partition: False, num_workers: 0, record_time: False, gpu_idx: [0], my_exp: True, epochs: 200, predict_epochs: 5, predict_alpha: 0.8, show_sign_flip: False, other_show_3d: False, npy_file_name: 4.3.2, npy_prefix: None, num_clients: 30, num_adv: 6, attack: MPAF, defense: Mean, attack_params: {'lamda': '1e5'}, defense_params: None, benchmark: False, num_training_sample: 60000, num_channels: 1, num_classes: 10, mean: (0.1307,), std: (0.3081,), device: cuda:0, output: ./logs/FedSGD/MNIST_lenet/iid/MPAF_Mean/200_30_6_0.01_2025-03-02_19-08-02.txt

Started on Sun Mar  2 19:08:02 2025
Generating new indices
Doing iid partition
iid partition finished
Data partitioned
Clients and server are initialized
Starting Training...
Epoch 0  	Train Acc: 0.0990	Train loss: 0.0722	Test Acc: 0.1674	Test loss: 22051867848931524608.0000
Epoch 1  	Train Acc: 0.1437	Train loss: 22316765665338466304.0000	Test Acc: 0.0980	Test loss: nan
Epoch 2  	Train Acc: 0.0896	Train loss: nan	Test Acc: 0.0980	Test loss: nan
Epoch 3  	Train Acc: 0.0833	Train loss: nan	Test Acc: 0.0980	Test loss: nan
Epoch 4  	Train Acc: 0.0781	Train loss: nan	Test Acc: 0.0980	Test loss: nan
Epoch 5  	Train Acc: 0.1052	Train loss: nan	Test Acc: 0.0980	Test loss: nan
Epoch 6  	Train Acc: 0.1073	Train loss: nan	Test Acc: 0.0980	Test loss: nan
Epoch 7  	Train Acc: 0.1094	Train loss: nan	Test Acc: 0.0980	Test loss: nan
